\chapter{Lezione 7}
\label{chap:lezione_07}

\begin{flushright}
\textit{Data: 17/10/2025}
\end{flushright}

\section{Ergodicità e Dinamica dei Sistemi}

Nello studio della meccanica statistica dei sistemi complessi, il punto di partenza per comprendere la dinamica è il concetto di \textbf{ergodicità}.
Un sistema si definisce ergodico se, durante la sua evoluzione temporale, è in grado di visitare tutti i microstati accessibili nello spazio delle fasi con una frequenza proporzionale alla loro probabilità termodinamica (distribuzione di Boltzmann). In termini pratici, questo implica l'equivalenza tra media temporale e media d'insieme (statistica).

Tuttavia, quando studiamo sistemi reali o simulazioni, dobbiamo confrontarci con due scale temporali fondamentali:
\begin{enumerate}
    \item \textbf{Tempo di osservazione ($t_{obs}$):} Il tempo fisico o computazionale che abbiamo a disposizione per misurare le proprietà del sistema.
    \item \textbf{Tempo ergodico ($t_{erg}$):} Il tempo caratteristico necessario al sistema per esplorare l'intero spazio delle fasi, superando eventuali barriere di potenziale.
\end{enumerate}

\noindent Un sistema si definisce ergodico, quindi, quando il tempo ergodico è comparabile con il tempo di osservazione.

\noindent Se $t_{obs} \ll t_{erg}$, il sistema si trova in una condizione di \textbf{rottura dell'ergodicità} (o ergodicità rotta). Il sistema rimane confinato ("intrappolato") in una sottoregione dello spazio delle fasi (uno stato metastabile) e le medie misurate non corrisponderanno a quelle termodinamiche di equilibrio. Questo fenomeno è noto come \textit{critical slowing down} quando ci si avvicina a una transizione di fase.

\subsection{Barriere Energetiche ed Entropiche}

Il meccanismo che impedisce al sistema di esplorare lo spazio delle fasi è la presenza di barriere nell'energia libera. Possiamo classificarle in due tipi:

\begin{itemize}
    \item \textbf{Barriere Energetiche:} Sono ostacoli dovuti a un aumento dell'energia interna $U$ (come in un sistema a doppia buca). Per superarle, il sistema deve attendere una fluttuazione termica sufficiente. Il tempo di scavalco segue tipicamente la legge di Arrhenius:
    
    \begin{equation}
    \tau \sim \tau_0 e^{\left(\frac{\Delta U}{k_B T}\right)}
    \end{equation}

    Se siamo a basse temperature o se la barriera è molto alta, il tempo di esplorazione diventa enorme. In tal caso, il sistema rimane intrappolato in una regione dello spazio delle fasi e l'ergodicità è rotta (o richiede tempi infiniti).
    
    \item \textbf{Barriere Entropiche:} Queste barriere non sono dovute a "muri" di energia, ma alla vastità dello spazio delle fasi. Immaginate un paesaggio energetico piatto (un "flat landscape"), simile a un campo da golf o al deserto del Sahara.
\end{itemize}

In una barriera entropica, il sistema non "vede" il gradiente di energia che lo guiderebbe verso il minimo. Deve muoversi per pura diffusione in uno spazio ad alta dimensionalità. Sebbene non ci siano muri energetici da scalare, la probabilità di imboccare casualmente la "strada stretta" che porta al minimo è esponenzialmente piccola. In questi casi, è l'entropia (il numero di stati) a intrappolare il sistema, non l'energia.

\subsection{Modello a 3-Spin}

Un esempio illuminante per comprendere la differenza tra barriere energetiche ed entropiche è il modello di spin con interazione a 3 corpi (p-spin con $p=3$).
L'Hamiltoniana (in approssimazione di campo medio) dipende dalla magnetizzazione $m$ come:

\begin{equation}
    H(m) \approx -N \frac{m^3}{6}
\end{equation}

Confrontiamo la dinamica di rilassamento verso il minimo (ferromagnetico, $m=1$) partendo da uno stato disordinato ($m \approx 0$):

\begin{itemize}
    \item \textbf{Modello a 2-spin (Curie-Weiss):} L'energia è $e(m) \sim -m^2$. La forza termodinamica è $F = -\frac{\partial e}{\partial m} \sim m$. Vicino a zero, c'è una pendenza lineare che "spinge" il sistema verso l'ordine.
    \item \textbf{Modello a 3-spin:} L'energia è $e(m) \sim -m^3$. La forza è $F = -\frac{\partial e}{\partial m} \sim m^2$.
\end{itemize}

Nel caso a 3-spin, vicino a $m=0$, la forza è nulla al primo ordine (la funzione è estremamente piatta). Il sistema, trovandosi in $m=0$, non percepisce alcuna spinta verso $m=1$. Anche se lo stato ordinato esiste ed è energeticamente favorevole, il sistema rimane bloccato in $m=0$ a causa della barriera entropica: non sa in che direzione muoversi perché il paesaggio è localmente piatto.

\subsection{Modello di Potts}

Il modello di Potts è una generalizzazione del modello di Ising in cui ogni spin $S_i$ può assumere $q$ valori discreti (chiamati spesso "colori"): $S_i \in \{1, 2, \dots, q\}$.
L'Hamiltoniana è definita come:

\begin{equation}
    H = -J \sum_{\langle i,j \rangle} \delta_{S_i, S_j}
\end{equation}

dove $\delta$ è la delta di Kronecker (l'energia diminuisce se due spin vicini hanno lo stesso colore).


L'ordine della transizione di fase nel modello di Potts dipende dal numero di stati $q$:
\begin{itemize}
    \item Per $q=2$: Il modello è isomorfo al modello di Ising. La transizione è del \textbf{secondo ordine} (continua).
    \item Per $q > 2$: La transizione diventa del \textbf{primo ordine} (discontinua).
\end{itemize}

\noindent Consideriamo il caso $q=3$ (o superiore). Analizzando l'energia libera in funzione del parametro d'ordine $m$ (che misura quanto un colore prevale sugli altri), si osserva un fenomeno di coesistenza di fasi.
Esistono due temperature critiche "locali" chiamate \textbf{punti spinodali}, oltre alla temperatura di transizione termodinamica $T_c$:

\begin{enumerate}
    \item \textbf{Spinodale Paramagnetica ($T_{sp}^+$):} Raffreddando il sistema, a questa temperatura appare per la prima volta un minimo locale (metastabile) corrispondente alla fase ordinata (ferromagnetica), mentre il minimo globale è ancora quello disordinato ($m=0$).
    \item \textbf{Spinodale Ferromagnetica ($T_{sp}^-$):} Riscaldando il sistema, a questa temperatura il minimo ferromagnetico diventa instabile e scompare.
\end{enumerate}

Tra queste due temperature, il sistema mostra \textbf{isteresi} e metastabilità. La transizione avviene "a salto" quando l'energia libera dei due minimi si incrocia a $T_c$.

\subsection{Nucleazione in Sistemi a Taglia Finita}

Nei modelli di campo medio ($N \to \infty$), le barriere di energia libera tra stati metastabili e stabili scalano con $N$ ($\Delta F \propto N$). Questo implica che il tempo di vita dello stato metastabile diverge ($\tau \sim e^N$), rendendo la metastabilità eterna: l'ergodicità è rotta rigorosamente.

Nei sistemi reali a dimensione finita $d$ (Finite Size Systems), la barriera è finita e il sistema può "scappare" dallo stato metastabile tramite il meccanismo della \textbf{nucleazione}.
Immaginiamo di formare una "goccia" (droplet) di raggio $R$ della fase stabile all'interno della fase metastabile. La variazione di energia libera ha due contributi:

\begin{equation}
    \Delta F(R) \sim \sigma R^{d-1} - \Delta f \cdot R^d
\end{equation}

\begin{itemize}
    \item \textbf{Termine di Superficie ($+\sigma R^{d-1}$):} Costo energetico dovuto alla tensione superficiale $\sigma$ tra le due fasi. Sfavorisce la goccia.
    \item \textbf{Termine di Volume ($-\Delta f \cdot R^d$):} Guadagno energetico dovuto al fatto che la fase interna alla goccia è termodinamicamente più stabile. Favorisce la goccia.
\end{itemize}

Esiste un \textbf{raggio critico} $R_c$.
\begin{itemize}
    \item Se $R < R_c$, il costo superficiale domina: la goccia tende a riassorbirsi.
    \item Se $R > R_c$, il guadagno di volume vince: la goccia cresce spontaneamente e invade tutto il sistema.
\end{itemize}

In dimensione finita, la barriera $\Delta F(R_c)$ è finita, quindi c'è sempre una probabilità non nulla che una fluttuazione termica crei una goccia critica. La metastabilità, in senso stretto, non esiste in sistemi a range finito (il sistema alla fine decade), ma i tempi possono essere astronomici.

\section{Sistemi Disordinati}


I sistemi disordinati sono caratterizzati da un'Hamiltoniana i cui parametri non sono costanti, ma variabili casuali estratte da una certa distribuzione di probabilità.
L'Hamiltoniana generica è:

\begin{equation}
    H(\vec{S}) = - \sum_{\langle i,j \rangle} J_{ij} S_i S_j - \sum_i h_i S_i
\end{equation}

Nei sistemi disordinati l'Hamiltoniana non è unica, ma esiste un ensamble di Hamiltoniane a causa delle variabili casuali.

Il disordine può manifestarsi in:
\begin{itemize}
    \item \textbf{Disordine nei legami ($J_{ij}$):} È il caso dei \textbf{Vetri di Spin} (Spin Glasses). Le interazioni possono essere sia ferromagnetiche ($J>0$) che antiferromagnetiche ($J~<~0$) distribuite casualmente.
    \item \textbf{Disordine nei campi ($h_i$):} \textbf{Random Field Ising Model} (RFIM). Ogni spin sente un campo locale che tende a orientarlo in una direzione casuale.
    \item \textbf{Diluizione:} Alcuni legami sono semplicemente assenti ($J_{ij}=0$ con probabilità $1-p$).
\end{itemize}

\subsection{La Frustrazione}
La caratteristica cruciale introdotta dal disordine (in particolare nei segni di $J_{ij}$) è la \textbf{frustrazione}.
Un sistema è frustrato quando è impossibile soddisfare contemporaneamente tutte le richieste energetiche locali (tutti i legami).

Esempio del triangolo: Consideriamo tre spin disposti a triangolo con interazioni antiferromagnetiche ($J<0$).
\begin{itemize}
    \item Lo spin 1 vuole essere opposto allo spin 2.
    \item Lo spin 2 vuole essere opposto allo spin 3.
    \item Lo spin 3 vuole essere opposto allo spin 1.
\end{itemize}
Non esiste una configurazione che soddisfi tutte e tre le condizioni (Up-Down-Up lascia il legame 1-3 insoddisfatto).

\begin{tcolorbox}[colback=yellow!25, colframe=yellow!75!orange, coltitle=black, title=\textbf{Frustrazione}]
La frustrazione si ha quando il prodotto lungo un circuito chiuso dei coupling è negativo:

\begin{equation}
    \prod J <0
\end{equation}
\end{tcolorbox}


La frustrazione genera un paesaggio energetico estremamente rugoso (\textbf{rugged landscape}) con moltissimi minimi locali quasi degeneri, rendendo la dinamica lenta e complessa.

\subsection{Media Annealed e Quenched}

Per studiare questi sistemi, dobbiamo calcolare le medie delle grandezze termodinamiche sul disordine. Distinguiamo due approcci fondamentali.

\subsubsection{Media Annealed}
Si assume che le variabili di disordine ($J_{ij}$) evolvano sulla stessa scala temporale degli spin $S_i$. Il disordine è in equilibrio termico con il sistema.
In questo caso, si media la funzione di partizione $Z$:

\begin{equation}
    \overline{Z} = \int dJ P(J) Z_J
\end{equation}

L'energia libera annealed è:
\begin{equation}
    F_{ann} = -k_B T \ln(\overline{Z})
\end{equation}
Questo approccio è matematicamente semplice, ma spesso fisicamente errato per i sistemi che ci interessano.

Per comprendere perché la media annealed fallisce, consideriamo un semplice modello matematico che illustra il peso delle configurazioni rare.
Supponiamo che la funzione di partizione $Z_J$, che dipende dalla realizzazione del disordine $J$, possa assumere due comportamenti nel limite termodinamico ($N \to \infty$):

\begin{enumerate}
    \item \textbf{Comportamento Tipico:} Si realizza con probabilità $1 - p \approx 1$. In questo caso la funzione di partizione vale:
    \begin{equation}
        Z_{typ} \sim e^{Nb}
    \end{equation}
    
    \item \textbf{Comportamento Raro:} Si realizza con una probabilità esponenzialmente piccola $p \sim e^{-Nc}$ (con $c > 0$). In questo caso, però, la funzione di partizione assume un valore eccezionalmente alto:
    \begin{equation}
        Z_{raro} \sim e^{Na} \quad \text{con } a > b
    \end{equation}
\end{enumerate}

Calcoliamo ora la media annealed $\overline{Z}$:
\begin{equation}
    \overline{Z} = p \cdot Z_{raro} + (1-p) \cdot Z_{typ} \approx e^{-Nc} \cdot e^{Na} + 1 \cdot e^{Nb}
\end{equation}
\begin{equation}
    \overline{Z} \approx e^{N(a-c)} + e^{Nb}
\end{equation}

Confrontiamo i due termini all'esponente. Se la configurazione rara è sufficientemente energetica tale che $a - c > b$, allora nel limite $N \to \infty$ il primo termine dominerà la somma, nonostante la sua probabilità di accadimento sia quasi nulla.
Calcolando l'energia libera annealed:
\begin{equation}
    F_{ann} \propto -\ln \overline{Z} \sim -N(a-c)
\end{equation}

Tuttavia, l'energia libera del sistema fisico "vero" (quella che misureremmo in laboratorio nel 99.9\% dei campioni) è quella associata al comportamento tipico:
\begin{equation}
    F_{typ} \propto -\ln Z_{typ} \sim -Nb
\end{equation}

Poiché $a-c > b$, otteniamo che $F_{ann} \neq F_{typ}$. La media annealed è dominata da eventi statisticamente irrilevanti (fluttuazioni giganti di $Z$) e non descrive lo stato termodinamico del sistema fisico.
Questo dimostra la necessità di calcolare la media del logaritmo (Quenched) e non il logaritmo della media.


\subsubsection{Media Quenched}
Si assume che il disordine sia fissato (congelato) su scale temporali molto più lunghe di quelle della dinamica degli spin. Per ogni realizzazione fissa del disordine, il sistema raggiunge l'equilibrio.
La grandezza fisica che si media non è $Z$, ma l'energia libera $F$ (o il logaritmo di $Z$), che è una grandezza estensiva e self-averaging:


\begin{equation}
    F_{quenched} = -k_B T \overline{\ln Z} 
\end{equation}

\noindent Dalla disuguaglianza di Jensen ($\overline{\ln x} \le \ln \overline{x}$), sappiamo che:
\begin{equation}
    F_{quenched} \ge F_{ann}
\end{equation}
La media annealed sottostima sempre l'energia libera vera, perché è dominata da realizzazioni rare del disordine che hanno una $Z$ eccezionalmente grande.

\noindent Calcolare direttamente $\overline{\ln Z}$ è analiticamente molto difficile. Si ricorre a un potente artificio matematico chiamato \textbf{Replica Trick}.
Sfruttiamo l'identità matematica:

\begin{equation}
    \overline{\ln Z} = \lim_{n \to 0} \frac{\overline{Z^n} - 1}{n}
\end{equation}

L'idea è calcolare la media del momento n-esimo della funzione di partizione, $\overline{Z^n}$, assumendo inizialmente che $n$ sia un numero intero positivo.
Dopo aver calcolato questa quantità per $n$ intero, si effettua una continuazione analitica per $n \to 0$. 
